{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "from scipy.io import wavfile\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "data_root = \"./dataset\"\n",
    "train = pd.read_csv(os.path.join(data_root, \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(data_root, \"sample_submission.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2, n_classes=41,\n",
    "                 use_mfcc=False, n_folds=10, learning_rate=0.0001,\n",
    "                 max_epochs=50, n_mfcc=20):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)\n",
    "def prepare_data(df, config, data_dir):\n",
    "    X = np.empty(shape=(df.shape[0], config.dim[0], config.dim[1], 1))\n",
    "    input_length = config.audio_length\n",
    "    for i, fname in enumerate(df.index):\n",
    "        #print(fname)\n",
    "        file_path = data_dir + fname\n",
    "        data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "\n",
    "        data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n",
    "        data = np.expand_dims(data, axis=-1)\n",
    "        X[i,] = data\n",
    "        if i%100==0: print(fname)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.71195017e+02  8.67218923e+01 -8.68484048e+00  1.10992938e+01\n -1.13603528e+00  6.67262492e+00 -4.58815642e-01  2.70545461e+00\n -6.28837325e-01  1.13116347e+00 -2.75643224e-01  7.98913112e-01\n  9.24784837e-02  6.11031499e-01  9.09000137e-02  6.07228257e-01\n  1.40003216e-02  6.77890730e-01  1.93926683e-01  3.94245631e-01\n  8.23013944e-02  1.73263664e-01 -9.86073703e-02  2.38401622e-01\n  9.51442925e-02  3.17948966e-01  1.08027023e-01  4.29151189e-01\n -6.16326547e-02  3.10527673e-01 -1.57109732e-01  1.34655422e-01\n -1.05907219e-01  2.53557759e-01 -2.18417807e-01  2.03774135e-01\n -4.94232983e-02  1.73134965e-01 -2.83320867e-02  1.83026096e-01]\n[-4.66033445e+02  8.23644621e+01 -1.38170029e+01  1.16376241e+01\n -2.57346918e+00  6.90062386e+00 -1.49834213e+00  2.88186548e+00\n -1.59544513e+00  6.68437534e-01 -1.10905199e+00  4.43983283e-01\n -2.79526323e-01  4.82756468e-01 -2.17242062e-01  6.52351035e-01\n -1.07604621e-01  8.49665019e-01  4.35129813e-01  6.16955592e-01\n  1.01423591e-01  3.60621854e-01 -1.47994690e-02  4.47456591e-01\n  3.21508439e-01  6.93250600e-01  4.74755080e-01  8.58310001e-01\n  1.62830116e-01  5.58956129e-01 -8.39521604e-02  4.12765677e-01\n -7.22855113e-02  4.34392941e-01 -1.29150336e-01  3.38411892e-01\n  7.10455334e-02  3.50736059e-01  1.95320009e-01  4.71749208e-01]\n"
     ]
    }
   ],
   "source": [
    "print(mean[:,0,0])\n",
    "print(np.mean(mean,axis=1)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221.14725199  87.56803837  39.99952489  24.405279    19.13094649\n  14.78184575  13.38119501  11.81655646  10.88142122  10.48501795\n   9.70191829   8.91325998   8.91491658   8.31850645   8.0877303\n   7.79807173   7.45621931   7.19477697   6.97909748   6.78732797\n   6.73065104   6.63933903   6.65777394   6.68400011   6.55432491\n   6.29839365   6.04186207   5.6929627    5.52577324   5.46193352\n   5.41468163   5.34608553   5.26354739   5.17490999   5.20304415\n   5.38430372   5.50170278   5.35272587   4.97838486   4.74544063]\n[203.28762364  75.79474719  47.82216709  27.83725255  22.54973322\n  17.48948832  16.75118865  14.35648827  13.64101721  13.23492617\n  12.62152191  12.06261458  11.9915152   11.92912788  11.6167816\n  11.59190331  11.251212    10.82318369  10.44781297  10.16843015\n  10.21739503  10.42982771  10.87505503  11.0720104   11.24129758\n  10.84473982  10.22632294   9.5676512    9.06891272   8.54451143\n   8.51562843   8.54343824   8.15479196   8.00608341   8.40899866\n   9.29868606   9.6540338    9.32221726   8.27964625   7.45993636]\n"
     ]
    }
   ],
   "source": [
    "print(std[:,0,0])\n",
    "print(np.mean(std,axis=1)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 173)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = std[:,:,0]\n",
    "std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('mean_std.npz', mean=mean,std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "read = np.load('mean_std.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 173)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read['mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.concatenate((a,a),1)[:,0:187]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.zeros([1,40,40])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 40)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1,40,40).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lr\n",
    "import os\n",
    "\n",
    "def trim_silence(audio, threshold=0.005, frame_length=512):\n",
    "    '''Removes silence at the beginning and end of a sample.'''\n",
    "    if audio.size < frame_length:\n",
    "        frame_length = audio.size\n",
    "    energy = lr.feature.rmse(audio, frame_length=frame_length)\n",
    "    frames = np.nonzero(energy > threshold)\n",
    "    indices = lr.core.frames_to_samples(frames)[1]\n",
    "    # Note: indices can be an empty array, if the whole audio was silence.\n",
    "    return audio[indices[0]:indices[-1]] if indices.size else audio\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    bins = np.linspace(-1, 1, classes)\n",
    "    quantized = np.digitize(mu_x, bins) - 1\n",
    "    return quantized\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "def process_data1():\n",
    "    sampling_rate = 16000\n",
    "    mono=True\n",
    "    classes = 256\n",
    "    dtype = torch.FloatTensor\n",
    "    ltype = torch.LongTensor\n",
    "    data_root = \"dataset\"\n",
    "    data_dir = os.path.join(data_root, \"audio_train\")\n",
    "    csv_file = pd.read_csv(os.path.join(data_root, \"train.csv\"))\n",
    "    LABELS = list(csv_file.label.unique())\n",
    "    label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "    print(\"create dataset from audio files at\", data_dir)\n",
    "    dataset_file = os.path.join(data_root, \"train.npy\")\n",
    "    processed_files = []\n",
    "    for i, filename in enumerate(csv_file[\"fname\"]):\n",
    "        #print(\"  processed \" + str(i) + \" of \" + str(csv_file.shape[0]) + \" files\")\n",
    "        file_data, _ = lr.load(path=os.path.join(data_dir, filename),\n",
    "                               sr=sampling_rate,\n",
    "                               mono=mono)\n",
    "        file_data = trim_silence(file_data)\n",
    "        # 把音频离散化为256类\n",
    "        quantized_data = quantize_data(file_data, classes).astype(dtype)\n",
    "        label = label_idx[csv_file[\"label\"][i]].astype(ltype)\n",
    "        processed_files.append((quantized_data, label))\n",
    "                               \n",
    "    np.savez(dataset_file, *processed_files)\n",
    "    print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataset from audio files at dataset/audio_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "process_data1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_length = model.receptive_field + model.output_length -1    #11138\n",
    "step_length = 5000\n",
    "target_length = model.output_length #5000\n",
    "data_root = \"dataset\"\n",
    "data_dir = os.path.join(data_root, \"audio_train\")\n",
    "dataset_file = os.path.join(data_root, \"train.npy.npz\")\n",
    "dataset_clip_file = os.path.join(data_root, \"train_clip.npy\")\n",
    "data = np.load(dataset_file, mmap_mode='r')\n",
    "processed_files =[]\n",
    "for i, (file_data, label) in enumerate(data):\n",
    "    file_len = len(file_data)\n",
    "    while(file_len>0):\n",
    "        if file_len < item_length and file_len>=512:\n",
    "            s = file_data\n",
    "            for i in range(int(item_length/file_len)):\n",
    "                s=np.concatenate((s,file_data))\n",
    "            file_data= s[:item_length]\n",
    "            processed_files.append((file_data, label))\n",
    "            file_data = file_data[step_length:]\n",
    "            file_len = -1\n",
    "        elif file_len >= item_length:\n",
    "            processed_files.append((file_data[:item_length], label))\n",
    "            file_data = file_data[step_length:]\n",
    "            file_len = len(file_data)\n",
    "        else : file_len = -1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"dataset\"\n",
    "data_dir = os.path.join(data_root, \"audio_train\")\n",
    "dataset_file = os.path.join(data_root, \"train.npy.npz\")\n",
    "data = np.load(dataset_file, mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072 224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560 363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4608 806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 1141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 1304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 2387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632 2727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632 2991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632 4446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 4463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632 4857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 5700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 6346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632 6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072 6585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 7447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 8305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632 8451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 8467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632 8994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 9264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "minn = 1e10\n",
    "maxx = -1\n",
    "for i, key in enumerate(data.files):\n",
    "\n",
    "    a, l = data[key]\n",
    "    c=len(a)\n",
    "    #print(c)\n",
    "    if c < 6000: print(c,i)\n",
    "    #if maxx < c: maxx = c\n",
    "    #if i==10: break\n",
    "print( maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9473"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max is "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
